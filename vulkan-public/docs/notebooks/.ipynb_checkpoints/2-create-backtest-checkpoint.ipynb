{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Using Vulkan\n",
    "\n",
    "This notebook will take you through all the steps in using Vulkan backtest a policy.\\\n",
    "Backtests are useful in estimating the performance of your policies.\\\n",
    "You can simulate different changes in the rules and compare their results before going to production.\n",
    "\n",
    "By the end of this tutorial, you will have:\n",
    "\n",
    "1. Created a new policy, which can be used for online and batch evaluation,\n",
    "2. Created a backtest using the batch interface,\n",
    "3. Downloaded and analysed the results.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import vulkan_public.cli.client as vulkan\n",
    "from vulkan_public.cli.context import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = Context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Creating a Policy\n",
    "\n",
    "We'll start by creating a simple policy, with no dependencies.\\\n",
    "In the \"create-policy\" notebook, we go through the details of this.\\\n",
    "The important part is: you can use the exact same code to create a policy for 1-by-1 runs and for backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_id = vulkan.policy.create_policy(\n",
    "    ctx,\n",
    "    name=\"Test Policy\",\n",
    "    description=\"Test Policy Description\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_version_id = vulkan.policy.create_policy_version(\n",
    "    ctx,\n",
    "    policy_id=policy_id,\n",
    "    version_name=\"v0.0.1\",\n",
    "    repository_path=\"examples/policies/simple/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Running the Backtest\n",
    "\n",
    "Now that our policy is ready, we can create a backtest.\\\n",
    "To do that, we just need some data. The file below has some samples in the format our policy expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./test/data/simple_bkt.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Now we just pass that data to the Vulkan Engine.\\\n",
    "A job will be created to evaluate the policy on each row of your data.\n",
    "\n",
    "The first time we backtest a policy, it'll take a few minutes to prepare the environment.\\\n",
    "After that, creating a new backtest is almost instant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = vulkan.backtest.upload_backtest_file(\n",
    "    ctx,\n",
    "    policy_version_id=policy_version_id,\n",
    "    file_path=\"test/data/simple_bkt.csv\",\n",
    "    file_format=\"CSV\",\n",
    "    schema={\"tax_id\": \"str\", \"score\": \"int\", \"default\": \"int\"},\n",
    ")\n",
    "file_id = file_info[\"uploaded_file_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vulkan.policy_version.create_backtest_workspace(ctx, policy_version_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_info = vulkan.backtest.create_backtest(\n",
    "    ctx,\n",
    "    policy_version_id=policy_version_id,\n",
    "    input_file_id=file_id,\n",
    "    config_variables=[\n",
    "        {\"SCORE_CUTOFF\": 500},\n",
    "        {\"SCORE_CUTOFF\": 700},\n",
    "    ],\n",
    "    metrics_config={\n",
    "        \"target_column\": \"default\",\n",
    "    }\n",
    ")\n",
    "\n",
    "backtest_id = backtest_info[\"backtest_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vulkan.backtest.poll_backtest_status(ctx, backtest_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Getting the results \n",
    "\n",
    "Backtest jobs are optimized for scalability.\\\n",
    "This means that they don't run instantaneously, but can run for large volumes of data.\\\n",
    "To make it easier to use, we have a function that waits until a job is finished and gets it's results.\n",
    "\n",
    "To get the outputs, we can query Vulkan using the Backtest ID.\\\n",
    "This will give us the results for all runs of this individual backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = vulkan.backtest.get_results(ctx, backtest_id)\n",
    "output_data = pd.DataFrame(output)\n",
    "output_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Automated Metrics for Backtests\n",
    "\n",
    "Vulkan can calculate a bunch a useful metrics about your backtests.\\\n",
    "This will happen automatically for each backtest, and can be useful to analyze your results.\n",
    "\n",
    "To start, you just need to tell Vulkan to calculate some metrics for the backtest you're creating.\\\n",
    "In each backtest you can specify:\n",
    "\n",
    "- A target variable: a reference value for each row. For now, we only support binary targets (0 or 1).\n",
    "- A time variable: a column that identifies the reference time for your data. For instance, this can be a \"month of entry\". This will be used to group results by time, allowing you to see how the results would have evolved.\n",
    "- Any number of columns to group by, which can be used to have more granular analyses.\n",
    "\n",
    "The metrics calculated depend on how you configure the backtest, and on what data you have.\\\n",
    "Let's look at an example where we only have a `target` column.\\\n",
    "Here, for each configuration in our backtest (identified by `backfill_id`) and for each different result (`status`), we can see the distribution of outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_job = vulkan.backtest.poll_backtest_metrics_job_status(ctx, backtest_id)\n",
    "metrics_df = pd.DataFrame(metrics_job[\"metrics\"])\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
