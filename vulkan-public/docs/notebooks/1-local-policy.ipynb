{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from vulkan_public.beam.local.runner import PolicyRunner\n",
    "from vulkan_public.core.policy import Policy\n",
    "from vulkan_public.schemas import DataSourceSpec\n",
    "from vulkan_public.spec.dependency import INPUT_NODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "\n",
    "We'll create a Parquet file with our input data, and a second file to act as a \"Data Source\".\n",
    "\n",
    "Data Sources bring external data into your workflow. \n",
    "This can be done by consulting a bureau, or by having some test data, like in our case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/simple_bkt_lg.csv\")\n",
    "df[\"month\"] = df[\"month\"].astype(str)\n",
    "df[\"tax_id\"] = df[\"tax_id\"].astype(str)\n",
    "\n",
    "df.to_parquet(\"input.parquet\")\n",
    "\n",
    "lookup_df = df[[\"tax_id\", \"score\"]]\n",
    "lookup_df.to_parquet(\"file_data_source.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Define the Policy\n",
    "\n",
    "This is all the code used to define the policy. \\\n",
    "In fact, in `docs/examples/policies/local/test_policy/policy.py` \n",
    "we use the exact same code to create our \"packaged\" version, \n",
    "which we'll use later for remote execution.\n",
    "\n",
    "There are a few key parts here:\n",
    "- `DataInputNode`: These nodes are used to bring data into your decision flows. Here, we'll use a local file, but this can later be replaced with an API or database without having to change the flow\n",
    "- `branch_condition` and `BranchNode`: \"Branches\" are how we make decisions in our policies. At a branch, you can have any number of possible outputs. In our case here, we write a function that returns \"approved\" if the score is greater than a cutoff.\n",
    "- `TerminateNode`: Terminate nodes are how we represent the final step in a policy, or the final decision. The `return_status` value is the final decision made. Here, we either approve or deny someone. We'll later see how this can be used to pass information to other systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from vulkan_public.spec.dependency import INPUT_NODE, Dependency\n",
    "from vulkan_public.spec.nodes import BranchNode, DataInputNode, TerminateNode\n",
    "from vulkan_public.spec.policy import PolicyDefinition\n",
    "\n",
    "sample_file_input = DataInputNode(\n",
    "    name=\"My Model Data Source\",\n",
    "    description=\"Query My Model using REST API\",\n",
    "    source=\"file-input:my-api-name:v0.0.1\",\n",
    "    dependencies={\"inputs\": Dependency(INPUT_NODE)},\n",
    ")\n",
    "\n",
    "\n",
    "# Branching node\n",
    "def branch_condition(context, scores, **kwargs):\n",
    "    context.log.info(scores)\n",
    "    if scores[\"score\"] > context.env.get(\"SCORE_CUTOFF\"):\n",
    "        return \"approved\"\n",
    "    return \"denied\"\n",
    "\n",
    "\n",
    "branch = BranchNode(\n",
    "    func=branch_condition,\n",
    "    name=\"branch\",\n",
    "    description=\"BranchNode data\",\n",
    "    dependencies={\n",
    "        \"scores\": Dependency(sample_file_input.name),\n",
    "    },\n",
    "    outputs=[\"approved\", \"denied\"],\n",
    ")\n",
    "\n",
    "approved = TerminateNode(\n",
    "    name=\"approved\",\n",
    "    description=\"TerminateNode data branch\",\n",
    "    return_status=\"APPROVED\",\n",
    "    dependencies={\"condition\": Dependency(\"branch\", \"approved\")},\n",
    ")\n",
    "\n",
    "denied = TerminateNode(\n",
    "    name=\"denied\",\n",
    "    description=\"TerminateNode data branch\",\n",
    "    return_status=\"DENIED\",\n",
    "    dependencies={\"condition\": Dependency(\"branch\", \"denied\")},\n",
    ")\n",
    "\n",
    "demo_policy = PolicyDefinition(\n",
    "    nodes=[\n",
    "        sample_file_input,\n",
    "        branch,\n",
    "        approved,\n",
    "        denied,\n",
    "    ],\n",
    "    components=[],\n",
    "    config_variables=[\"SCORE_CUTOFF\"],\n",
    "    input_schema={\"tax_id\": str},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy.from_definition(demo_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Run the Policy Locally \n",
    "\n",
    "The entire policy can be visualized and the run locally.\n",
    "\n",
    "To do that, we'll just have to do two things:\n",
    "1. Create a schema, telling Vulkan where to get data for the data sources;\n",
    "2. Set a value for our score \"cutoff\": the minimum score to be Approved;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_schema = {\n",
    "    \"name\": \"file-input:my-api-name:v0.0.1\",\n",
    "    \"keys\": [\"tax_id\"],\n",
    "    \"source\": {\n",
    "        \"path\": \"file_data_source.parquet\",\n",
    "    },\n",
    "    \"caching\": {\n",
    "        \"enabled\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "data_sources = [\n",
    "    DataSourceSpec.model_validate(test_file_schema),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = PolicyRunner(policy, staging_path=\"./output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Visualizing the flow of information\n",
    "\n",
    "We can visualize our policy locally, at all times. \\\n",
    "This can show us how the clients are being treated and where we're making each decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Running\n",
    "\n",
    "Now we're ready to run our policy.\n",
    "\n",
    "Let's start with a single example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_variables = {\"SCORE_CUTOFF\": 500}\n",
    "\n",
    "result = runner.run(\n",
    "    input_data={\"tax_id\": \"1\"},\n",
    "    data_sources=data_sources,\n",
    "    config_variables=config_variables,\n",
    ")\n",
    "\n",
    "print(\"Here are our results:\\n\")\n",
    "result.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Running for a bunch of data\n",
    "\n",
    "We can run for 1 example, or for a bunch, just as easily. \\\n",
    "To run for a batch of data, we just need to pass the input data with a file. \\\n",
    "Let's pass in the input file we created at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_results = runner.run_batch(\n",
    "    input_data_path=\"input.parquet\",\n",
    "    data_sources=data_sources,\n",
    "    config_variables=config_variables,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
