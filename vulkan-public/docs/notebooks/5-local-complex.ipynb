{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from vulkan_public.beam.local.runner import PolicyRunner\n",
    "from vulkan_public.core.policy import Policy\n",
    "from vulkan_public.schemas import DataSourceSpec\n",
    "from vulkan_public.spec.dependency import INPUT_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE_A_ID = \"api:data-source-a:v1\"\n",
    "MODEL_A_ID = \"api:model-a:v1\"\n",
    "DATA_SOURCE_B_ID = \"api:data-source-b:v23\"\n",
    "MODEL_B_ID = \"api:model-b-serasa-teste-etc-etc:v34\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "\n",
    "We'll create a Parquet file with our input data, and a second file to act as a \"Data Source\".\n",
    "\n",
    "Data Sources bring external data into your workflow. \n",
    "This can be done by consulting a bureau, or by having some test data, like in our case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_a_test_schema = {\n",
    "    \"name\": DATA_SOURCE_A_ID,\n",
    "    \"keys\": [\"tax_id\"],\n",
    "    \"source\": {\n",
    "        \"path\": \"data_source_a.parquet\",\n",
    "    },\n",
    "}\n",
    "\n",
    "model_a_test_schema = {\n",
    "    \"name\": MODEL_A_ID,\n",
    "    \"keys\": [\"tax_id\"],\n",
    "    \"source\": {\n",
    "        \"path\": \"data_source_model_a.parquet\",\n",
    "    },\n",
    "}\n",
    "\n",
    "data_sources = [\n",
    "    DataSourceSpec.model_validate(data_source_a_test_schema),\n",
    "    DataSourceSpec.model_validate(model_a_test_schema),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16326/3174337014.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_source_a[\"valid\"] = np.random.choice(\n",
      "/tmp/ipykernel_16326/3174337014.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_source_b[\"valid\"] = np.random.choice(\n",
      "/tmp/ipykernel_16326/3174337014.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_b[\"score\"] = 1000 - model_b[\"score\"]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/simple_bkt_lg.csv\")\n",
    "df[\"month\"] = df[\"month\"].astype(str)\n",
    "df[\"tax_id\"] = df[\"tax_id\"].astype(str)\n",
    "\n",
    "df.to_parquet(\"input.parquet\")\n",
    "\n",
    "data_source_a = df[[\"tax_id\"]]\n",
    "data_source_a[\"valid\"] = np.random.choice(\n",
    "    [True, False], size=data_source_a.shape[0], p=[0.5, 0.5]\n",
    ")\n",
    "data_source_a.to_parquet(\"data_source_a.parquet\")\n",
    "\n",
    "model_a = df[[\"tax_id\", \"score\"]]\n",
    "model_a.to_parquet(\"data_source_model_a.parquet\")\n",
    "\n",
    "\n",
    "data_source_b = df[[\"tax_id\"]]\n",
    "data_source_b[\"valid\"] = np.random.choice(\n",
    "    [True, False], size=data_source_b.shape[0], p=[0.8, 0.2]\n",
    ")\n",
    "data_source_b.to_parquet(\"data_source_b.parquet\")\n",
    "\n",
    "model_b = df[[\"tax_id\", \"score\"]]\n",
    "model_b[\"score\"] = 1000 - model_b[\"score\"]\n",
    "model_b.to_parquet(\"data_source_model_b.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Define the Policy\n",
    "\n",
    "This is all the code used to define the policy. \\\n",
    "In fact, in `docs/examples/policies/local/test_policy/policy.py` \n",
    "we use the exact same code to create our \"packaged\" version, \n",
    "which we'll use later for remote execution.\n",
    "\n",
    "There are a few key parts here:\n",
    "- `DataInputNode`: These nodes are used to bring data into your decision flows. Here, we'll use a local file, but this can later be replaced with an API or database without having to change the flow\n",
    "- `branch_condition` and `BranchNode`: \"Branches\" are how we make decisions in our policies. At a branch, you can have any number of possible outputs. In our case here, we write a function that returns \"approved\" if the score is greater than a cutoff.\n",
    "- `TerminateNode`: Terminate nodes are how we represent the final step in a policy, or the final decision. The `return_status` value is the final decision made. Here, we either approve or deny someone. We'll later see how this can be used to pass information to other systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from vulkan_public.spec.dependency import INPUT_NODE, Dependency\n",
    "from vulkan_public.spec.nodes import (\n",
    "    BranchNode,\n",
    "    DataInputNode,\n",
    "    TerminateNode,\n",
    "    TransformNode,\n",
    ")\n",
    "from vulkan_public.spec.policy import PolicyDefinition\n",
    "\n",
    "CONTINUE = \"CONTINUE\"\n",
    "\n",
    "\n",
    "class Status(Enum):\n",
    "    DENY_NO_DATA_A = \"DENY_NO_DATA_A\"\n",
    "    DENY_SCORE_A = \"DENY_SCORE_A\"\n",
    "    APPROVE = \"APPROVE\"\n",
    "\n",
    "\n",
    "# START: Data Source + Model A\n",
    "data_source_a = DataInputNode(\n",
    "    name=\"data_source_a\",\n",
    "    description=\"My first Data Source\",\n",
    "    source=DATA_SOURCE_A_ID,\n",
    "    dependencies={\"inputs\": Dependency(INPUT_NODE)},\n",
    ")\n",
    "\n",
    "check_source_a = BranchNode(\n",
    "    name=\"check_source_a\",\n",
    "    func=lambda source_a: CONTINUE\n",
    "    if source_a[\"valid\"]\n",
    "    else Status.DENY_NO_DATA_A.value,\n",
    "    dependencies={\"source_a\": Dependency(data_source_a.name)},\n",
    "    outputs=[CONTINUE, Status.DENY_NO_DATA_A.value],\n",
    ")\n",
    "\n",
    "deny_no_data_a = TerminateNode(\n",
    "    name=Status.DENY_NO_DATA_A.value,\n",
    "    return_status=Status.DENY_NO_DATA_A,\n",
    "    dependencies={\n",
    "        \"condition\": Dependency(check_source_a.name, Status.DENY_NO_DATA_A.value)\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "preprocess_model_a_request = TransformNode(\n",
    "    name=\"preprocess_model_a_request\",\n",
    "    description=\"Data Sources currently need to receive a structure that contains all the keys in the root level\",\n",
    "    func=lambda inputs, source_a, condition: {**inputs, **source_a},\n",
    "    dependencies={\n",
    "        \"inputs\": Dependency(INPUT_NODE),\n",
    "        \"source_a\": Dependency(data_source_a.name),\n",
    "        \"condition\": Dependency(check_source_a.name, CONTINUE),\n",
    "    },\n",
    ")\n",
    "\n",
    "model_a = DataInputNode(\n",
    "    name=\"Model A\",\n",
    "    description=\"Get score from Model A\",\n",
    "    source=MODEL_A_ID,\n",
    "    dependencies={\"data\": Dependency(preprocess_model_a_request.name)},\n",
    ")\n",
    "\n",
    "\n",
    "def _decide_model_a(context, response_model_a) -> str:\n",
    "    if response_model_a is None:\n",
    "        return Status.DENY_SCORE_A.value\n",
    "\n",
    "    elif response_model_a[\"score\"] >= context.env.get(\"THRESHOLD_MODEL_A\"):\n",
    "        return Status.DENY_SCORE_A.value\n",
    "\n",
    "    return Status.APPROVE.value\n",
    "\n",
    "\n",
    "decide_model_a = BranchNode(\n",
    "    name=\"decide_model_a\",\n",
    "    func=_decide_model_a,\n",
    "    dependencies={\"response_model_a\": Dependency(model_a.name)},\n",
    "    outputs=[Status.APPROVE.value, Status.DENY_SCORE_A.value],\n",
    ")\n",
    "\n",
    "deny_score_a = TerminateNode(\n",
    "    name=Status.DENY_SCORE_A.value,\n",
    "    return_status=Status.DENY_SCORE_A,\n",
    "    dependencies={\n",
    "        \"condition\": Dependency(decide_model_a.name, Status.DENY_SCORE_A.value)\n",
    "    },\n",
    ")\n",
    "# END Model with Source A\n",
    "\n",
    "approve = TerminateNode(\n",
    "    name=Status.APPROVE.value,\n",
    "    return_status=Status.APPROVE,\n",
    "    dependencies={\"condition\": Dependency(decide_model_a.name, Status.APPROVE.value)},\n",
    ")\n",
    "\n",
    "demo_policy = PolicyDefinition(\n",
    "    nodes=[\n",
    "        data_source_a,\n",
    "        check_source_a,\n",
    "        deny_no_data_a,\n",
    "        preprocess_model_a_request,\n",
    "        model_a,\n",
    "        decide_model_a,\n",
    "        deny_score_a,\n",
    "        approve,\n",
    "    ],\n",
    "    components=[],\n",
    "    config_variables=[\"THRESHOLD_MODEL_A\"],\n",
    "    input_schema={\"tax_id\": str},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy.from_definition(demo_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Run the Policy Locally \n",
    "\n",
    "The entire policy can be visualized and the run locally.\n",
    "\n",
    "To do that, we'll just have to do two things:\n",
    "1. Create a schema, telling Vulkan where to get data for the data sources;\n",
    "2. Set a value for our score \"cutoff\": the minimum score to be Approved;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Visualizing the flow of information\n",
    "\n",
    "We can visualize our policy locally, at all times. \\\n",
    "This can show us how the clients are being treated and where we're making each decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = PolicyRunner(policy, staging_path=\"./output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"510pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 510.43 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 506.43,-472 506.43,4 -4,4\"/>\n",
       "<!-- input_node -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>input_node</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"325.14\" cy=\"-450\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"325.14\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input_node</text>\n",
       "</g>\n",
       "<!-- data_source_a -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>data_source_a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"273.14\" cy=\"-378\" rx=\"76.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"273.14\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">data_source_a</text>\n",
       "</g>\n",
       "<!-- input_node&#45;&gt;data_source_a -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input_node&#45;&gt;data_source_a</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.55,-432.05C306.29,-423.63 298.61,-413.28 291.69,-403.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"294.39,-401.73 285.61,-395.79 288.77,-405.9 294.39,-401.73\"/>\n",
       "</g>\n",
       "<!-- preprocess_model_a_request -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>preprocess_model_a_request</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"358.14\" cy=\"-234\" rx=\"144.07\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"358.14\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">preprocess_model_a_request</text>\n",
       "</g>\n",
       "<!-- input_node&#45;&gt;preprocess_model_a_request -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>input_node&#45;&gt;preprocess_model_a_request</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M339.12,-432.04C346.33,-422.18 354.39,-409.13 358.14,-396 371.12,-350.61 366.97,-295.03 362.65,-262.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.08,-261.75 361.2,-252.35 359.15,-262.74 366.08,-261.75\"/>\n",
       "</g>\n",
       "<!-- check_source_a -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>check_source_a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"229.14\" cy=\"-306\" rx=\"81.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.14\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">check_source_a</text>\n",
       "</g>\n",
       "<!-- data_source_a&#45;&gt;check_source_a -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>data_source_a&#45;&gt;check_source_a</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M262.49,-360.05C257.38,-351.92 251.14,-342 245.45,-332.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"248.29,-330.88 240,-324.28 242.36,-334.6 248.29,-330.88\"/>\n",
       "</g>\n",
       "<!-- data_source_a&#45;&gt;preprocess_model_a_request -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>data_source_a&#45;&gt;preprocess_model_a_request</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M290.78,-360.01C300.34,-350.14 311.85,-337.09 320.14,-324 332.58,-304.36 342.67,-279.95 349.32,-261.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"352.63,-262.8 352.66,-252.2 346.03,-260.47 352.63,-262.8\"/>\n",
       "</g>\n",
       "<!-- DENY_NO_DATA_A -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>DENY_NO_DATA_A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"98.14\" cy=\"-234\" rx=\"98.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.14\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">DENY_NO_DATA_A</text>\n",
       "</g>\n",
       "<!-- check_source_a&#45;&gt;DENY_NO_DATA_A -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>check_source_a&#45;&gt;DENY_NO_DATA_A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M199.42,-289.12C181.09,-279.32 157.36,-266.65 137.49,-256.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.13,-252.93 128.66,-251.31 135.83,-259.11 139.13,-252.93\"/>\n",
       "</g>\n",
       "<!-- check_source_a&#45;&gt;preprocess_model_a_request -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>check_source_a&#45;&gt;preprocess_model_a_request</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M258.41,-289.12C276.13,-279.5 298.95,-267.12 318.29,-256.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"320.07,-259.64 327.19,-251.8 316.73,-253.49 320.07,-259.64\"/>\n",
       "</g>\n",
       "<!-- Model A -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Model A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"358.14\" cy=\"-162\" rx=\"48.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"358.14\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model A</text>\n",
       "</g>\n",
       "<!-- preprocess_model_a_request&#45;&gt;Model A -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>preprocess_model_a_request&#45;&gt;Model A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M358.14,-215.7C358.14,-207.98 358.14,-198.71 358.14,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.64,-190.1 358.14,-180.1 354.64,-190.1 361.64,-190.1\"/>\n",
       "</g>\n",
       "<!-- decide_model_a -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decide_model_a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"358.14\" cy=\"-90\" rx=\"83.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"358.14\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">decide_model_a</text>\n",
       "</g>\n",
       "<!-- Model A&#45;&gt;decide_model_a -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>Model A&#45;&gt;decide_model_a</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M358.14,-143.7C358.14,-135.98 358.14,-126.71 358.14,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.64,-118.1 358.14,-108.1 354.64,-118.1 361.64,-118.1\"/>\n",
       "</g>\n",
       "<!-- DENY_SCORE_A -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>DENY_SCORE_A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"277.14\" cy=\"-18\" rx=\"87.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"277.14\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">DENY_SCORE_A</text>\n",
       "</g>\n",
       "<!-- decide_model_a&#45;&gt;DENY_SCORE_A -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>decide_model_a&#45;&gt;DENY_SCORE_A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M338.95,-72.41C328.53,-63.41 315.49,-52.14 304.07,-42.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.33,-39.6 296.48,-35.71 301.76,-44.9 306.33,-39.6\"/>\n",
       "</g>\n",
       "<!-- APPROVE -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>APPROVE</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"440.14\" cy=\"-18\" rx=\"57.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"440.14\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">APPROVE</text>\n",
       "</g>\n",
       "<!-- decide_model_a&#45;&gt;APPROVE -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>decide_model_a&#45;&gt;APPROVE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M377.57,-72.41C388.27,-63.28 401.71,-51.81 413.38,-41.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"415.8,-44.38 421.13,-35.23 411.25,-39.06 415.8,-44.38\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f4a521c0310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Running\n",
    "\n",
    "Now we're ready to run our policy.\n",
    "\n",
    "Let's start with a single example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are our results:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_node': [{'tax_id': '1'}],\n",
       " 'result': [{'status': 'DENY_NO_DATA_A'}, {'status': 'DENY_SCORE_A'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_variables = {\"THRESHOLD_MODEL_A\": 650}\n",
    "\n",
    "result = runner.run(\n",
    "    input_data={\"tax_id\": \"1\"},\n",
    "    data_sources=data_sources,\n",
    "    config_variables=config_variables,\n",
    ")\n",
    "\n",
    "print(\"Here are our results:\\n\")\n",
    "result.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Running for a bunch of data\n",
    "\n",
    "We can run for 1 example, or for a bunch, just as easily. \\\n",
    "To run for a batch of data, we just need to pass the input data with a file. \\\n",
    "Let's pass in the input file we created at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.72 s, sys: 742 ms, total: 4.46 s\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_results = runner.run_batch(\n",
    "    input_data_path=\"input.parquet\",\n",
    "    data_sources=data_sources,\n",
    "    config_variables=config_variables,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backfill_id</th>\n",
       "      <th>key</th>\n",
       "      <th>status</th>\n",
       "      <th>input_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>f0369ba55a60b5bc5bc8666a964c395c</td>\n",
       "      <td>DENY_NO_DATA_A</td>\n",
       "      <td>{'tax_id': '0'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>60a146574a1ec5f09a27e1f15ae95ded</td>\n",
       "      <td>DENY_NO_DATA_A</td>\n",
       "      <td>{'tax_id': '1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>761f36e599f6ca3cfb859271468973f2</td>\n",
       "      <td>DENY_NO_DATA_A</td>\n",
       "      <td>{'tax_id': '2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>3254c1565be80b4fe68c057671204ff6</td>\n",
       "      <td>DENY_SCORE_A</td>\n",
       "      <td>{'tax_id': '3'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>0e16afcc463ccb97987fd290aa35dc9d</td>\n",
       "      <td>DENY_SCORE_A</td>\n",
       "      <td>{'tax_id': '4'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>53861153a4b25a166752c788cf1d6e36</td>\n",
       "      <td>APPROVE</td>\n",
       "      <td>{'tax_id': '995'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>7fd9223d882ffd7bdcd47b6a58992371</td>\n",
       "      <td>DENY_NO_DATA_A</td>\n",
       "      <td>{'tax_id': '996'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>b41eaa06a9f79346369d7ebe486df932</td>\n",
       "      <td>DENY_SCORE_A</td>\n",
       "      <td>{'tax_id': '997'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>f4e11cf9a984c8554f09aa7720c6a7b8</td>\n",
       "      <td>DENY_NO_DATA_A</td>\n",
       "      <td>{'tax_id': '998'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1743082522112218</td>\n",
       "      <td>a8fe85a819ccdaf75ee3013672cc0e9b</td>\n",
       "      <td>DENY_NO_DATA_A</td>\n",
       "      <td>{'tax_id': '999'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          backfill_id                               key          status  \\\n",
       "0    1743082522112218  f0369ba55a60b5bc5bc8666a964c395c  DENY_NO_DATA_A   \n",
       "1    1743082522112218  60a146574a1ec5f09a27e1f15ae95ded  DENY_NO_DATA_A   \n",
       "2    1743082522112218  761f36e599f6ca3cfb859271468973f2  DENY_NO_DATA_A   \n",
       "3    1743082522112218  3254c1565be80b4fe68c057671204ff6    DENY_SCORE_A   \n",
       "4    1743082522112218  0e16afcc463ccb97987fd290aa35dc9d    DENY_SCORE_A   \n",
       "..                ...                               ...             ...   \n",
       "995  1743082522112218  53861153a4b25a166752c788cf1d6e36         APPROVE   \n",
       "996  1743082522112218  7fd9223d882ffd7bdcd47b6a58992371  DENY_NO_DATA_A   \n",
       "997  1743082522112218  b41eaa06a9f79346369d7ebe486df932    DENY_SCORE_A   \n",
       "998  1743082522112218  f4e11cf9a984c8554f09aa7720c6a7b8  DENY_NO_DATA_A   \n",
       "999  1743082522112218  a8fe85a819ccdaf75ee3013672cc0e9b  DENY_NO_DATA_A   \n",
       "\n",
       "            input_node  \n",
       "0      {'tax_id': '0'}  \n",
       "1      {'tax_id': '1'}  \n",
       "2      {'tax_id': '2'}  \n",
       "3      {'tax_id': '3'}  \n",
       "4      {'tax_id': '4'}  \n",
       "..                 ...  \n",
       "995  {'tax_id': '995'}  \n",
       "996  {'tax_id': '996'}  \n",
       "997  {'tax_id': '997'}  \n",
       "998  {'tax_id': '998'}  \n",
       "999  {'tax_id': '999'}  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_results.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Ramping it up: Two sources, two models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Preparing our new data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_b_test_schema = {\n",
    "    \"name\": DATA_SOURCE_B_ID,\n",
    "    \"keys\": [\"tax_id\"],\n",
    "    \"source\": {\n",
    "        \"path\": \"data_source_b.parquet\",\n",
    "    },\n",
    "}\n",
    "\n",
    "model_b_test_schema = {\n",
    "    \"name\": MODEL_B_ID,\n",
    "    \"keys\": [\"tax_id\"],\n",
    "    \"source\": {\n",
    "        \"path\": \"data_source_model_b.parquet\",\n",
    "    },\n",
    "}\n",
    "\n",
    "data_sources = [\n",
    "    DataSourceSpec.model_validate(data_source_a_test_schema),\n",
    "    DataSourceSpec.model_validate(model_a_test_schema),\n",
    "    DataSourceSpec.model_validate(data_source_b_test_schema),\n",
    "    DataSourceSpec.model_validate(model_b_test_schema),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_check_source_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 40\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Status\u001b[38;5;241m.\u001b[39mDENY_NO_DATA_A\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CONTINUE\n\u001b[1;32m     38\u001b[0m check_source_a \u001b[38;5;241m=\u001b[39m BranchNode(\n\u001b[1;32m     39\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_source_a\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 40\u001b[0m     func\u001b[38;5;241m=\u001b[39m\u001b[43m_check_source_a\u001b[49m,\n\u001b[1;32m     41\u001b[0m     dependencies\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_a\u001b[39m\u001b[38;5;124m\"\u001b[39m: Dependency(data_source_a\u001b[38;5;241m.\u001b[39mname)},\n\u001b[1;32m     42\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[CONTINUE, Status\u001b[38;5;241m.\u001b[39mDENY_NO_DATA_A\u001b[38;5;241m.\u001b[39mvalue],\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m deny_no_data_a \u001b[38;5;241m=\u001b[39m TerminateNode(\n\u001b[1;32m     46\u001b[0m     name\u001b[38;5;241m=\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDENY_NO_DATA_A\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m     47\u001b[0m     return_status\u001b[38;5;241m=\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDENY_NO_DATA_A,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     },\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     54\u001b[0m preprocess_model_a_request \u001b[38;5;241m=\u001b[39m TransformNode(\n\u001b[1;32m     55\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocess_model_a_request\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     56\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Sources currently need to receive a structure that contains all the keys in the root level\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     },\n\u001b[1;32m     63\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name '_check_source_a' is not defined"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from vulkan_public.spec.dependency import INPUT_NODE, Dependency\n",
    "from vulkan_public.spec.nodes import (\n",
    "    BranchNode,\n",
    "    DataInputNode,\n",
    "    TerminateNode,\n",
    "    TransformNode,\n",
    ")\n",
    "from vulkan_public.spec.policy import PolicyDefinition\n",
    "\n",
    "CONTINUE = \"CONTINUE\"\n",
    "\n",
    "\n",
    "class Status(Enum):\n",
    "    DENY_NO_DATA_A = \"DENY_NO_DATA_A\"\n",
    "    DENY_SCORE_A = \"DENY_SCORE_A\"\n",
    "    DENY_NO_DATA_B = \"DENY_NO_DATA_B\"\n",
    "    DENY_SCORE_B = \"DENY_SCORE_B\"\n",
    "    APPROVE = \"APPROVE\"\n",
    "\n",
    "\n",
    "# START: Data Source + Model A\n",
    "data_source_a = DataInputNode(\n",
    "    name=\"data_source_a\",\n",
    "    description=\"My first Data Source\",\n",
    "    source=DATA_SOURCE_A_ID,\n",
    "    dependencies={\"inputs\": Dependency(INPUT_NODE)},\n",
    ")\n",
    "\n",
    "\n",
    "def check_source_a(source_a) -> str:\n",
    "    if not source_a[\"valid\"]:\n",
    "        return Status.DENY_NO_DATA_A.value\n",
    "    return CONTINUE\n",
    "\n",
    "\n",
    "check_source_a = BranchNode(\n",
    "    name=\"check_source_a\",\n",
    "    func=_check_source_a,\n",
    "    dependencies={\"source_a\": Dependency(data_source_a.name)},\n",
    "    outputs=[CONTINUE, Status.DENY_NO_DATA_A.value],\n",
    ")\n",
    "\n",
    "deny_no_data_a = TerminateNode(\n",
    "    name=Status.DENY_NO_DATA_A.value,\n",
    "    return_status=Status.DENY_NO_DATA_A,\n",
    "    dependencies={\n",
    "        \"condition\": Dependency(check_source_a.name, Status.DENY_NO_DATA_A.value)\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "preprocess_model_a_request = TransformNode(\n",
    "    name=\"preprocess_model_a_request\",\n",
    "    description=\"Data Sources currently need to receive a structure that contains all the keys in the root level\",\n",
    "    func=lambda inputs, source_a, condition: {**inputs, **source_a},\n",
    "    dependencies={\n",
    "        \"inputs\": Dependency(INPUT_NODE),\n",
    "        \"source_a\": Dependency(data_source_a.name),\n",
    "        \"condition\": Dependency(check_source_a.name, CONTINUE),\n",
    "    },\n",
    ")\n",
    "\n",
    "model_a = DataInputNode(\n",
    "    name=\"Model A\",\n",
    "    description=\"Get score from Model A\",\n",
    "    source=MODEL_A_ID,\n",
    "    dependencies={\"data\": Dependency(preprocess_model_a_request.name)},\n",
    ")\n",
    "\n",
    "\n",
    "def _decide_model_a(context, response_model_a) -> str:\n",
    "    if response_model_a is None:\n",
    "        return Status.DENY_SCORE_A.value\n",
    "\n",
    "    elif response_model_a[\"score\"] >= context.env.get(\"THRESHOLD_MODEL_A\"):\n",
    "        return Status.DENY_SCORE_A.value\n",
    "\n",
    "    return CONTINUE\n",
    "\n",
    "\n",
    "decide_model_a = BranchNode(\n",
    "    name=\"decide_model_a\",\n",
    "    func=_decide_model_a,\n",
    "    dependencies={\"response_model_a\": Dependency(model_a.name)},\n",
    "    outputs=[CONTINUE, Status.DENY_SCORE_A.value],\n",
    ")\n",
    "\n",
    "\n",
    "deny_score_a = TerminateNode(\n",
    "    name=Status.DENY_SCORE_A.value,\n",
    "    return_status=Status.DENY_SCORE_A,\n",
    "    dependencies={\n",
    "        \"condition\": Dependency(decide_model_a.name, Status.DENY_SCORE_A.value)\n",
    "    },\n",
    ")\n",
    "# END Model with Source A\n",
    "\n",
    "# Start Data Source and Model B\n",
    "make_source_b_request = TransformNode(\n",
    "    name=\"make_source_b_request\",\n",
    "    func=lambda inputs, condition: inputs,\n",
    "    dependencies={\n",
    "        \"inputs\": Dependency(INPUT_NODE),\n",
    "        \"condition\": Dependency(decide_model_a.name, CONTINUE),\n",
    "    },\n",
    ")\n",
    "\n",
    "data_source_b = DataInputNode(\n",
    "    name=\"data_source_b\",\n",
    "    description=\"The Second Data Source!\",\n",
    "    source=DATA_SOURCE_B_ID,\n",
    "    dependencies={\"data\": Dependency(make_source_b_request.name)},\n",
    ")\n",
    "\n",
    "check_source_b = BranchNode(\n",
    "    name=\"check_source_b\",\n",
    "    func=lambda data: CONTINUE if data[\"valid\"] else Status.DENY_NO_DATA_B.value,\n",
    "    dependencies={\"data\": Dependency(data_source_b.name)},\n",
    "    outputs=[CONTINUE, Status.DENY_NO_DATA_B.value],\n",
    ")\n",
    "\n",
    "deny_no_data_b = TerminateNode(\n",
    "    name=Status.DENY_NO_DATA_B.value,\n",
    "    return_status=Status.DENY_NO_DATA_B,\n",
    "    dependencies={\n",
    "        \"condition\": Dependency(check_source_b.name, Status.DENY_NO_DATA_B.value)\n",
    "    },\n",
    ")\n",
    "\n",
    "preprocess_model_b_request = TransformNode(\n",
    "    name=\"preprocess_model_b_request\",\n",
    "    description=\"Data Sources currently need to receive a structure that contains all the keys in the root level\",\n",
    "    func=lambda inputs, source_a, source_b, condition: {\n",
    "        **inputs,\n",
    "        **source_a,\n",
    "        **source_b,\n",
    "    },\n",
    "    dependencies={\n",
    "        \"inputs\": Dependency(INPUT_NODE),\n",
    "        \"source_a\": Dependency(data_source_a.name),\n",
    "        \"source_b\": Dependency(data_source_b.name),\n",
    "        \"condition\": Dependency(check_source_b.name, CONTINUE),\n",
    "    },\n",
    ")\n",
    "\n",
    "model_b = DataInputNode(\n",
    "    name=\"model_b\",\n",
    "    description=\"Get score from Model B using two data sources\",\n",
    "    source=MODEL_B_ID,\n",
    "    dependencies={\"data\": Dependency(preprocess_model_b_request.name)},\n",
    ")\n",
    "\n",
    "\n",
    "def _decide_model_b(context, model_response) -> str:\n",
    "    if model_response is None:\n",
    "        return Status.DENY_SCORE_B.value\n",
    "\n",
    "    elif model_response[\"score\"] >= context.env.get(\"THRESHOLD_MODEL_B\"):\n",
    "        return Status.DENY_SCORE_B.value\n",
    "\n",
    "    return Status.APPROVE.value\n",
    "\n",
    "\n",
    "decide_model_b = BranchNode(\n",
    "    name=\"decide_model_b\",\n",
    "    func=_decide_model_b,\n",
    "    dependencies={\"model_response\": Dependency(model_b.name)},\n",
    "    outputs=[Status.APPROVE.value, Status.DENY_SCORE_B.value],\n",
    ")\n",
    "\n",
    "\n",
    "deny_score_b = TerminateNode(\n",
    "    name=Status.DENY_SCORE_B.value,\n",
    "    return_status=Status.DENY_SCORE_B,\n",
    "    dependencies={\n",
    "        \"condition\": Dependency(decide_model_b.name, Status.DENY_SCORE_B.value)\n",
    "    },\n",
    ")\n",
    "# END Model with Sources A and B\n",
    "\n",
    "approve = TerminateNode(\n",
    "    name=Status.APPROVE.value,\n",
    "    return_status=Status.APPROVE,\n",
    "    dependencies={\"condition\": Dependency(decide_model_b.name, Status.APPROVE.value)},\n",
    ")\n",
    "\n",
    "demo_policy = PolicyDefinition(\n",
    "    nodes=[\n",
    "        data_source_a,\n",
    "        check_source_a,\n",
    "        deny_no_data_a,\n",
    "        preprocess_model_a_request,\n",
    "        model_a,\n",
    "        decide_model_a,\n",
    "        deny_score_a,\n",
    "        make_source_b_request,\n",
    "        data_source_b,\n",
    "        check_source_b,\n",
    "        deny_no_data_b,\n",
    "        preprocess_model_b_request,\n",
    "        model_b,\n",
    "        decide_model_b,\n",
    "        deny_score_b,\n",
    "        approve,\n",
    "    ],\n",
    "    components=[],\n",
    "    config_variables=[\"THRESHOLD_MODEL_A\", \"THRESHOLD_MODEL_B\"],\n",
    "    input_schema={\"tax_id\": str},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy.from_definition(demo_policy)\n",
    "runner = PolicyRunner(policy, staging_path=\"./output/\")\n",
    "runner.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_results = runner.run_batch(\n",
    "    input_data_path=\"input.parquet\",\n",
    "    data_sources=data_sources,\n",
    "    config_variables={\"THRESHOLD_MODEL_A\": 650, \"THRESHOLD_MODEL_B\": 700},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results.data.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
